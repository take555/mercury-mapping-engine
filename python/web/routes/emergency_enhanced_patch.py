# enhanced.pyã®_handle_enhanced_analysis_post()é–¢æ•°ã®å…ˆé ­ã«ä»¥ä¸‹ã‚’è¿½åŠ 

import logging
import sys
import time

# ç·Šæ€¥ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¨­å®š
debug_logger = logging.getLogger('enhanced_emergency_debug')
debug_logger.setLevel(logging.INFO)
if not debug_logger.handlers:
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    console_handler = logging.StreamHandler(sys.stdout)
    console_formatter = logging.Formatter('%(asctime)s - EMERGENCY - %(message)s')
    console_handler.setFormatter(console_formatter)
    debug_logger.addHandler(console_handler)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    try:
        file_handler = logging.FileHandler('/app/logs/emergency_debug.log', encoding='utf-8')
        file_handler.setFormatter(console_formatter)
        debug_logger.addHandler(file_handler)
    except:
        pass

def clean_field_name(field_name):
    """BOMæ–‡å­—ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’ä¿®æ­£"""
    if isinstance(field_name, str):
        return field_name.replace('\ufeff', '').strip()
    elif isinstance(field_name, tuple):
        return tuple(str(item).replace('\ufeff', '').strip() for item in field_name)
    return str(field_name).replace('\ufeff', '').strip()

def log_performance_step(step_name, start_time=None):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬"""
    current_time = time.time()
    if start_time:
        elapsed = current_time - start_time
        debug_logger.info(f"âœ… {step_name} å®Œäº†: {elapsed:.2f}ç§’")
        return current_time
    else:
        debug_logger.info(f"ğŸš€ {step_name} é–‹å§‹")
        return current_time

# _handle_enhanced_analysis_post()é–¢æ•°å†…ã§ä½¿ç”¨ä¾‹:

def _handle_enhanced_analysis_post():
    debug_logger.info("=" * 60)
    debug_logger.info("ğŸš€ ENHANCED ANALYSIS START (EMERGENCY DEBUG)")
    debug_logger.info("=" * 60)
    
    total_start = time.time()
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        step1_start = log_performance_step("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†")
        
        # ... æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚³ãƒ¼ãƒ‰ ...
        
        step1_end = log_performance_step("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†", step1_start)
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: EngineåˆæœŸåŒ–
        step2_start = log_performance_step("MappingEngineåˆæœŸåŒ–")
        
        # ... æ—¢å­˜ã®EngineåˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰ ...
        
        step2_end = log_performance_step("MappingEngineåˆæœŸåŒ–", step2_start)
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: CSVåˆ†æ
        step3_start = log_performance_step("CSVåˆ†æ")
        
        # ... æ—¢å­˜ã®CSVåˆ†æã‚³ãƒ¼ãƒ‰ ...
        
        step3_end = log_performance_step("CSVåˆ†æ", step3_start)
        debug_logger.info(f"CSVåˆ†æçµæœ: Aç¤¾{analysis_a['total_rows']}è¡Œ, Bç¤¾{analysis_b['total_rows']}è¡Œ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒãƒƒãƒãƒ³ã‚°
        step4_start = log_performance_step("Brute Force Matching")
        
        # ... æ—¢å­˜ã®ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† ...
        
        step4_end = log_performance_step("Brute Force Matching", step4_start)
        debug_logger.info(f"ãƒãƒƒãƒãƒ³ã‚°çµæœ: {len(matches)}ä»¶")
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æï¼ˆã“ã“ãŒé…ã„å¯èƒ½æ€§å¤§ï¼‰
        step5_start = log_performance_step("ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ")
        
        if matches:
            debug_logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°é–‹å§‹: {len(matches)}ä»¶ã®ãƒãƒƒãƒã‹ã‚‰åˆ†æ")
            
            # æ—¢å­˜ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†
            field_mapping_result = engine.field_mapper.analyze_field_mappings_from_matches(
                matches, analysis_a['headers'], analysis_b['headers']
            )
            
            debug_logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ç”Ÿãƒ‡ãƒ¼ã‚¿å–å¾—: {type(field_mapping_result)}")
            
            # BOMæ–‡å­—é™¤å»ã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            if isinstance(field_mapping_result, list):
                enhanced_mappings = []
                for mapping in field_mapping_result:
                    if isinstance(mapping, dict):
                        cleaned_mapping = {
                            'field_a': clean_field_name(mapping.get('field_a', '')),
                            'field_b': clean_field_name(mapping.get('field_b', '')),
                            'confidence': mapping.get('confidence', 0.0),
                            'sample_count': mapping.get('sample_count', 0),
                            'field_type': mapping.get('field_type', 'unknown')
                        }
                        enhanced_mappings.append(cleaned_mapping)
                    elif isinstance(mapping, tuple):
                        # ã‚¿ãƒ—ãƒ«å½¢å¼ã®å ´åˆ
                        field_a = clean_field_name(mapping[0]) if len(mapping) > 0 else 'unknown'
                        field_b = clean_field_name(mapping[1]) if len(mapping) > 1 else 'unknown'
                        cleaned_mapping = {
                            'field_a': field_a,
                            'field_b': field_b,
                            'confidence': 0.0,
                            'sample_count': 1,
                            'field_type': 'tuple_converted'
                        }
                        enhanced_mappings.append(cleaned_mapping)
            elif isinstance(field_mapping_result, dict):
                enhanced_mappings = []
                for key, value in field_mapping_result.items():
                    if 'â†’' in str(key):
                        parts = str(key).split('â†’')
                        field_a = clean_field_name(parts[0])
                        field_b = clean_field_name(parts[1]) if len(parts) > 1 else 'unknown'
                    else:
                        field_a = clean_field_name(key)
                        field_b = 'unknown'
                    
                    confidence = value.get('confidence', 0.0) if isinstance(value, dict) else 0.0
                    
                    cleaned_mapping = {
                        'field_a': field_a,
                        'field_b': field_b,
                        'confidence': confidence,
                        'sample_count': value.get('sample_count', 1) if isinstance(value, dict) else 1,
                        'field_type': 'dict_converted'
                    }
                    enhanced_mappings.append(cleaned_mapping)
            else:
                enhanced_mappings = []
            
            debug_logger.info(f"ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒãƒƒãƒ”ãƒ³ã‚°: {len(enhanced_mappings)}ä»¶")
            
        step5_end = log_performance_step("ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ", step5_start)
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: ã‚µãƒãƒªãƒ¼ä½œæˆï¼ˆã“ã“ã‚‚é…ã„å¯èƒ½æ€§ï¼‰
        step6_start = log_performance_step("ãƒãƒƒãƒ”ãƒ³ã‚°ã‚µãƒãƒªãƒ¼ä½œæˆ")
        
        # ... æ—¢å­˜ã®ã‚µãƒãƒªãƒ¼ä½œæˆå‡¦ç† ...
        
        step6_end = log_performance_step("ãƒãƒƒãƒ”ãƒ³ã‚°ã‚µãƒãƒªãƒ¼ä½œæˆ", step6_start)
        
        # ã‚¹ãƒ†ãƒƒãƒ—7: HTMLç”Ÿæˆï¼ˆæœ€ã‚‚é…ã„å¯èƒ½æ€§ï¼‰
        step7_start = log_performance_step("HTMLç”Ÿæˆ")
        
        # ... æ—¢å­˜ã®HTMLç”Ÿæˆå‡¦ç† ...
        
        step7_end = log_performance_step("HTMLç”Ÿæˆ", step7_start)
        
        total_time = time.time() - total_start
        debug_logger.info("=" * 60)
        debug_logger.info(f"ğŸ TOTAL TIME: {total_time:.2f}ç§’")
        debug_logger.info("=" * 60)
        
        return html
        
    except Exception as e:
        debug_logger.error(f"ğŸ’¥ CRITICAL ERROR: {e}")
        debug_logger.error(f"ERROR TRACEBACK: {traceback.format_exc()}")
        raise