"""
Mercury Mapping Engine - Card Matcher
ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
"""
import re
from typing import Dict, List, Tuple, Any, Optional
from utils.text_similarity import TextSimilarity
from utils.logger import analysis_logger, performance_logger


class CardMatcher:
    """ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°å°‚ç”¨ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config=None):
        self.config = config or {}
        self.match_threshold = self.config.get('card_match_threshold', 0.75)
        self.name_similarity_threshold = self.config.get('card_name_similarity_threshold', 0.8)
        self.price_similarity_threshold = self.config.get('price_similarity_threshold', 0.9)
        self.text_similarity = TextSimilarity()

    def find_matching_cards(self, data_a, data_b, headers_a, headers_b):
        """æ–°ç”Ÿä»£ãƒãƒƒãƒãƒ³ã‚° - åŠ›æŠ€ã®ã¿"""
        return self.brute_force_matching(data_a, data_b, headers_a, headers_b)

    def identify_card_name_fields(self, headers: List[str]) -> List[str]:
        """ã‚«ãƒ¼ãƒ‰åã¨æ€ã‚ã‚Œã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®š"""
        name_patterns = [
            'ã‚«ãƒ¼ãƒ‰å', 'åå‰', 'åç§°', 'name', 'card_name', 'title', 'product_name',
            'item_name', 'ã‚«ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«', 'ã‚¢ã‚¤ãƒ†ãƒ å', 'ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆå', 'ã‚«ãƒ¼ãƒ‰', 'card'
        ]

        candidates = []
        for header in headers:
            for pattern in name_patterns:
                if pattern.lower() in header.lower() or header.lower() in pattern.lower():
                    candidates.append(header)
                    break

        return candidates if candidates else headers[:3]  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€åˆã®3ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰

    def identify_price_fields(self, headers: List[str]) -> List[str]:
        """ä¾¡æ ¼ã¨æ€ã‚ã‚Œã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®š"""
        price_patterns = [
            'ä¾¡æ ¼', 'å€¤æ®µ', 'price', 'é‡‘é¡', 'amount', 'cost', 'buy_price', 'sell_price',
            'è²©å£²ä¾¡æ ¼', 'è²·å–ä¾¡æ ¼', 'ç¨è¾¼', 'ç¨æŠœ', 'yen', 'å††', 'æ–™é‡‘'
        ]

        candidates = []
        for header in headers:
            for pattern in price_patterns:
                if pattern.lower() in header.lower():
                    candidates.append(header)
                    break

        return candidates

    def _calculate_match_score(self, row_a: Dict, row_b: Dict,
                               name_fields_a: List[str], name_fields_b: List[str],
                               price_fields_a: List[str], price_fields_b: List[str],
                               headers_a: List[str], headers_b: List[str]) -> Dict[str, Any]:
        """ãƒãƒƒãƒã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        match_score = 0
        match_details = {}

        # æ–¹æ³•1: ã‚«ãƒ¼ãƒ‰åã®é¡ä¼¼åº¦
        name_similarity = self._calculate_card_name_similarity(
            row_a, row_b, name_fields_a, name_fields_b
        )
        if name_similarity > self.name_similarity_threshold:
            match_score += name_similarity * 0.7
            match_details['name_match'] = name_similarity

        # æ–¹æ³•2: ä¾¡æ ¼ã®ä¸€è‡´ï¼ˆè£œåŠ©åˆ¤å®šï¼‰
        price_similarity = self._calculate_price_similarity(
            row_a, row_b, price_fields_a, price_fields_b
        )
        if price_similarity > self.price_similarity_threshold:
            match_score += price_similarity * 0.3
            match_details['price_match'] = price_similarity

        # æ–¹æ³•3: è¤‡æ•°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç·åˆåˆ¤å®š
        overall_similarity = self._calculate_overall_similarity(
            row_a, row_b, headers_a, headers_b
        )
        if overall_similarity > 0.6:
            match_score += overall_similarity * 0.2
            match_details['overall_match'] = overall_similarity

        return {
            'score': match_score,
            'details': match_details
        }

    def _calculate_card_name_similarity(self, row_a: Dict, row_b: Dict,
                                        name_fields_a: List[str], name_fields_b: List[str]) -> float:
        """ã‚«ãƒ¼ãƒ‰åã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        max_similarity = 0

        for field_a in name_fields_a:
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a:
                continue

            for field_b in name_fields_b:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b:
                    continue

                # è¤‡æ•°ã®é¡ä¼¼åº¦è¨ˆç®—æ‰‹æ³•ã‚’ä½¿ç”¨
                similarities = [
                    self.text_similarity.calculate_exact_similarity(value_a, value_b),
                    self.text_similarity.calculate_fuzzy_similarity(value_a, value_b),
                    self.text_similarity.calculate_partial_similarity(value_a, value_b)
                ]

                current_similarity = max(similarities)
                max_similarity = max(max_similarity, current_similarity)

        return max_similarity

    def _calculate_price_similarity(self, row_a: Dict, row_b: Dict,
                                    price_fields_a: List[str], price_fields_b: List[str]) -> float:
        """ä¾¡æ ¼ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        for field_a in price_fields_a:
            value_a = self._extract_numeric_value(row_a.get(field_a, ''))
            if value_a is None:
                continue

            for field_b in price_fields_b:
                value_b = self._extract_numeric_value(row_b.get(field_b, ''))
                if value_b is None:
                    continue

                # ä¾¡æ ¼ãŒå®Œå…¨ä¸€è‡´ã¾ãŸã¯éå¸¸ã«è¿‘ã„å ´åˆ
                if abs(value_a - value_b) < 0.01:
                    return 1.0
                elif value_a > 0 and value_b > 0:
                    diff_ratio = abs(value_a - value_b) / max(value_a, value_b)
                    if diff_ratio < 0.1:  # 10%ä»¥å†…ã®å·®
                        return 1.0 - diff_ratio

        return 0.0

    def _calculate_overall_similarity(self, row_a: Dict, row_b: Dict,
                                      headers_a: List[str], headers_b: List[str]) -> float:
        """å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã®ç·åˆçš„ãªé¡ä¼¼åº¦"""
        similarities = []

        for field_a in headers_a[:5]:  # æœ€åˆã®5ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ãƒã‚§ãƒƒã‚¯
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a:
                continue

            for field_b in headers_b[:5]:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b:
                    continue

                similarity = self.text_similarity.calculate_fuzzy_similarity(value_a, value_b)
                if similarity > 0.7:
                    similarities.append(similarity)

        return sum(similarities) / len(similarities) if similarities else 0.0

    def _extract_numeric_value(self, value_str: str) -> Optional[float]:
        """æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º"""
        if not value_str:
            return None

        # æ•°å­—ã¨ãƒ”ãƒªã‚ªãƒ‰ã€ã‚«ãƒ³ãƒã®ã¿æŠ½å‡º
        numeric_str = re.sub(r'[^\d.,]', '', str(value_str))
        numeric_str = numeric_str.replace(',', '')

        try:
            return float(numeric_str)
        except ValueError:
            return None

    def _remove_duplicate_matches(self, matches: List[Dict]) -> List[Dict]:
        """é‡è¤‡ã™ã‚‹ãƒãƒƒãƒã‚’é™¤å»"""
        used_a = set()
        used_b = set()
        unique_matches = []

        for match in matches:
            if match['row_a_index'] not in used_a and match['row_b_index'] not in used_b:
                unique_matches.append(match)
                used_a.add(match['row_a_index'])
                used_b.add(match['row_b_index'])

        return unique_matches

    def analyze_match_quality(self, matches: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒãƒƒãƒãƒ³ã‚°å“è³ªã‚’åˆ†æ"""
        if not matches:
            return {
                'total_matches': 0,
                'average_score': 0.0,
                'high_quality_matches': 0,
                'medium_quality_matches': 0,
                'low_quality_matches': 0
            }

        # ã‚¹ã‚³ã‚¢ã‚’å®‰å…¨ã«å–å¾—
        scores = []
        for match in matches:
            score = (match.get('match_score') or
                     match.get('similarity') or
                     match.get('score') or
                     0.0)
            try:
                scores.append(float(score))
            except (ValueError, TypeError):
                scores.append(0.0)

        if not scores:
            scores = [0.0]

        avg_score = sum(scores) / len(scores)
        high_quality = len([s for s in scores if s > 0.8])
        medium_quality = len([s for s in scores if 0.6 <= s <= 0.8])
        low_quality = len([s for s in scores if s < 0.6])

        return {
            'total_matches': len(matches),
            'average_score': round(avg_score, 3),
            'high_quality_matches': high_quality,
            'medium_quality_matches': medium_quality,
            'low_quality_matches': low_quality
        }

    def brute_force_matching(self, data_a: List[Dict], data_b: List[Dict],
                             headers_a: List[str], headers_b: List[str],
                             max_sample_size: int = 100,
                             similarity_mode: str = 'library',  # 'library' or 'ai'
                             ai_manager=None) -> List[Dict[str, Any]]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åŠ›æŠ€ãƒãƒƒãƒãƒ³ã‚°: ãƒ©ã‚¤ãƒ–ãƒ©ãƒª vs AI ã§é¡ä¼¼åº¦è¨ˆç®—ã‚’åˆ‡ã‚Šæ›¿ãˆ

        Args:
            data_a: Aç¤¾ãƒ‡ãƒ¼ã‚¿
            data_b: Bç¤¾ãƒ‡ãƒ¼ã‚¿
            headers_a: Aç¤¾ãƒ˜ãƒƒãƒ€ãƒ¼
            headers_b: Bç¤¾ãƒ˜ãƒƒãƒ€ãƒ¼
            max_sample_size: æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
            similarity_mode: 'library' (Python libs) or 'ai' (Claude API)
            ai_manager: AI Manager instance (similarity_mode='ai'æ™‚ã«å¿…è¦)

        Returns:
            é«˜ç²¾åº¦ãƒãƒƒãƒãƒ³ã‚°çµæœ
        """
        performance_logger.start_timer('brute_force_matching')

        mode_info = {
            'library': 'ğŸ Python Library Mode - é«˜é€Ÿãƒ»å®‰ä¾¡',
            'ai': 'ğŸ¤– Claude AI Mode - é«˜ç²¾åº¦ãƒ»æ„å‘³ç†è§£'
        }

        analysis_logger.logger.info(f"ğŸ”¥ Brute Force Matching é–‹å§‹ - {mode_info.get(similarity_mode, similarity_mode)}")

        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        sample_a = data_a[:max_sample_size]
        sample_b = data_b[:max_sample_size]

        matches = []
        field_correlation_matrix = {}

        analysis_logger.logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: Aç¤¾{len(sample_a)}è¡Œ Ã— Bç¤¾{len(sample_b)}è¡Œ")
        analysis_logger.logger.info(f"âš™ï¸ é¡ä¼¼åº¦è¨ˆç®—ãƒ¢ãƒ¼ãƒ‰: {similarity_mode}")

        for i, row_a in enumerate(sample_a):
            best_matches = []

            for j, row_b in enumerate(sample_b):
                # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ
                if similarity_mode == 'library':
                    field_match_results = self._compare_all_fields_library(
                        row_a, row_b, headers_a, headers_b
                    )
                elif similarity_mode == 'ai':
                    field_match_results = self._compare_all_fields_ai(
                        row_a, row_b, headers_a, headers_b, ai_manager
                    )
                else:
                    raise ValueError(f"Unknown similarity_mode: {similarity_mode}")

                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œãƒãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                self._update_field_correlation_matrix(
                    field_correlation_matrix, field_match_results
                )

                # è¡Œå…¨ä½“ã®ãƒãƒƒãƒã‚¹ã‚³ã‚¢è¨ˆç®—
                total_score = self._calculate_brute_force_score(field_match_results)

                if total_score > 0.6:
                    best_matches.append({
                        'row_a_index': i,
                        'row_b_index': j,
                        'row_a_data': row_a,
                        'row_b_data': row_b,
                        'match_score': total_score,
                        'field_matches': field_match_results,
                        'similarity_mode': similarity_mode,
                        'match_details': {
                            'matched_fields_count': len([fm for fm in field_match_results if fm['similarity'] > 0.7]),
                            'total_fields_compared': len(field_match_results),
                            'best_field_match': max(field_match_results,
                                                    key=lambda x: x['similarity']) if field_match_results else None
                        }
                    })

            # å„Aç¤¾è¡Œã«å¯¾ã—ã¦æœ€è‰¯ã®ãƒãƒƒãƒã®ã¿ä¿æŒ
            if best_matches:
                best_match = max(best_matches, key=lambda x: x['match_score'])
                matches.append(best_match)

        # é‡è¤‡é™¤å»
        unique_matches = self._remove_duplicate_matches_brute_force(matches)

        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œçµ±è¨ˆ
        field_mapping_stats = self._analyze_field_correlations(field_correlation_matrix)

        analysis_logger.logger.info(f"ğŸ¯ Brute Forceçµæœ: {len(unique_matches)}ä»¶ã®ãƒãƒƒãƒ")
        analysis_logger.logger.info(f"ğŸ“ˆ ç™ºè¦‹ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œ: {len(field_mapping_stats)}çµ„")

        # çµæœã«ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’è¿½åŠ 
        for match in unique_matches:
            match['discovered_field_mappings'] = field_mapping_stats
            match['analysis_mode'] = similarity_mode

        performance_logger.end_timer('brute_force_matching')
        return unique_matches

    def _compare_all_fields_library(self, row_a: Dict, row_b: Dict,
                                    headers_a: List[str], headers_b: List[str]) -> List[Dict]:
        """ğŸ Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ™ãƒ¼ã‚¹ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ"""
        field_matches = []

        for field_a in headers_a:
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a or len(value_a) < 2:
                continue

            for field_b in headers_b:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b or len(value_b) < 2:
                    continue

                # è¤‡æ•°æ‰‹æ³•ã§å¾¹åº•æ¯”è¼ƒ
                similarities = self._calculate_comprehensive_similarity(value_a, value_b)
                max_similarity = max(similarities.values())

                if max_similarity > 0.5:
                    field_matches.append({
                        'field_a': field_a,
                        'field_b': field_b,
                        'value_a': value_a,
                        'value_b': value_b,
                        'similarity': max_similarity,
                        'similarity_details': similarities,
                        'match_type': self._classify_match_type(value_a, value_b, similarities),
                        'calculation_method': 'library'
                    })

        return field_matches

    def _compare_all_fields_ai(self, row_a: Dict, row_b: Dict,
                               headers_a: List[str], headers_b: List[str],
                               ai_manager) -> List[Dict]:
        """ğŸ¤– Claude AIãƒ™ãƒ¼ã‚¹ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ"""
        if not ai_manager:
            analysis_logger.logger.warning("AI Manager not provided, falling back to library mode")
            return self._compare_all_fields_library(row_a, row_b, headers_a, headers_b)

        field_matches = []

        # ãƒãƒƒãƒå‡¦ç†ã§AIåˆ†æï¼ˆåŠ¹ç‡åŒ–ï¼‰
        field_pairs = []
        for field_a in headers_a:
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a or len(value_a) < 2:
                continue

            for field_b in headers_b:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b or len(value_b) < 2:
                    continue

                field_pairs.append({
                    'field_a': field_a,
                    'field_b': field_b,
                    'value_a': value_a,
                    'value_b': value_b
                })

        # AIåˆ†æå®Ÿè¡Œ
        if field_pairs:
            ai_results = self._batch_ai_similarity_analysis(field_pairs, ai_manager)

            for i, pair in enumerate(field_pairs):
                ai_result = ai_results.get(i, {})
                similarity = ai_result.get('similarity', 0.0)

                if similarity > 0.5:
                    field_matches.append({
                        'field_a': pair['field_a'],
                        'field_b': pair['field_b'],
                        'value_a': pair['value_a'],
                        'value_b': pair['value_b'],
                        'similarity': similarity,
                        'ai_reasoning': ai_result.get('reasoning', ''),
                        'match_type': ai_result.get('match_type', 'ai_determined'),
                        'calculation_method': 'ai',
                        'ai_confidence': ai_result.get('confidence', similarity)
                    })

        return field_matches

    def _batch_ai_similarity_analysis(self, field_pairs: List[Dict], ai_manager) -> Dict:
        """ãƒãƒƒãƒã§AIé¡ä¼¼åº¦åˆ†æå®Ÿè¡Œ"""
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            prompt = self._build_similarity_analysis_prompt(field_pairs)

            # Claude APIå‘¼ã³å‡ºã—
            result = ai_manager.claude_client.call_api(
                prompt,
                model='claude-3-haiku-20240307'  # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ã§åŠ¹ç‡åŒ–
            )

            if result['success']:
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
                return self._parse_ai_similarity_response(result['content'])
            else:
                analysis_logger.logger.error(f"AI similarity analysis failed: {result.get('error')}")
                return {}

        except Exception as e:
            analysis_logger.logger.error(f"AI similarity analysis error: {e}")
            return {}

    def _build_similarity_analysis_prompt(self, field_pairs: List[Dict]) -> str:
        """AIé¡ä¼¼åº¦åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        pairs_text = ""
        for i, pair in enumerate(field_pairs[:20]):  # æœ€å¤§20ãƒšã‚¢ãšã¤å‡¦ç†
            pairs_text += f"""
{i}: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å "{pair['field_a']}" vs "{pair['field_b']}"
    å€¤ã®ä¾‹: "{pair['value_a']}" vs "{pair['value_b']}"
"""

        prompt = f"""
ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒšã‚¢ã«ã¤ã„ã¦ã€é¡ä¼¼åº¦ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ã€‘
{pairs_text}

ã€åˆ¤å®šåŸºæº–ã€‘
1. æ„å‘³çš„é¡ä¼¼æ€§ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®æ„å‘³ï¼‰
2. ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ä¸€è‡´åº¦
3. ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã®æ•´åˆæ€§
4. å€¤ã®å†…å®¹ã®é¡ä¼¼æ€§

ã€å›ç­”å½¢å¼ã€‘
JSONå½¢å¼ã§å„ãƒšã‚¢ã®åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{{
  "0": {{
    "similarity": 0.85,
    "reasoning": "attackã¨APã¯ä¸¡æ–¹ã¨ã‚‚æ”»æ’ƒåŠ›ã‚’è¡¨ã—ã€æ•°å€¤ã‚‚ä¸€è‡´",
    "match_type": "semantic_match",
    "confidence": 0.9
  }},
  "1": {{ ... }}
}}

é¡ä¼¼åº¦ã¯0.0-1.0ã§è©•ä¾¡ã—ã€0.7ä»¥ä¸Šã‚’é«˜é¡ä¼¼åº¦ã¨ã—ã¦åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
"""
        return prompt

    def _parse_ai_similarity_response(self, content: str) -> Dict:
        """AIå¿œç­”ã®JSONãƒ‘ãƒ¼ã‚¹"""
        try:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                import json
                return json.loads(json_match.group())
            else:
                analysis_logger.logger.warning("AI response does not contain valid JSON")
                return {}
        except Exception as e:
            analysis_logger.logger.error(f"Failed to parse AI response: {e}")
            return {}

    # æ—¢å­˜ã®_calculate_comprehensive_similarityç­‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãã®ã¾ã¾ä¿æŒ
