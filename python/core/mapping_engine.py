"""
Mercury Mapping Engine - Main Mapping Engine
çµ±åˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
"""
from typing import Dict, List, Tuple, Any, Optional
from .csv_analyzer import CSVAnalyzer
from .card_matcher import CardMatcher
from .field_mapper import FieldMapper
from utils.logger import analysis_logger, performance_logger


class MappingEngine:
    """çµ±åˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config=None):
        self.config = config or {}
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.csv_analyzer = CSVAnalyzer(self.config)
        self.card_matcher = CardMatcher(self.config)
        self.field_mapper = FieldMapper(self.config)
        
        analysis_logger.logger.info("MappingEngine initialized with modular components")
    
    def analyze_csv_files(self, filepath_a: str, filepath_b: str, 
                         full_analysis: bool = True) -> Dict[str, Any]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ"""
        performance_logger.start_timer('full_csv_analysis')
        
        try:
            if full_analysis:
                analysis_a = self.csv_analyzer.analyze_file_full(filepath_a)
                analysis_b = self.csv_analyzer.analyze_file_full(filepath_b)
            else:
                analysis_a = self.csv_analyzer.analyze_file(filepath_a)
                analysis_b = self.csv_analyzer.analyze_file(filepath_b)
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if 'error' in analysis_a:
                return {'error': f"Aç¤¾CSVã‚¨ãƒ©ãƒ¼: {analysis_a['error']}"}
            
            if 'error' in analysis_b:
                return {'error': f"Bç¤¾CSVã‚¨ãƒ©ãƒ¼: {analysis_b['error']}"}
            
            # CSVæ§‹é€ ã®æ¤œè¨¼
            validation_a = self.csv_analyzer.validate_csv_structure(
                analysis_a['headers'], analysis_a.get('full_data', analysis_a['sample_data'])
            )
            validation_b = self.csv_analyzer.validate_csv_structure(
                analysis_b['headers'], analysis_b.get('full_data', analysis_b['sample_data'])
            )
            
            result = {
                'analysis_a': analysis_a,
                'analysis_b': analysis_b,
                'validation_a': validation_a,
                'validation_b': validation_b,
                'analysis_type': 'full' if full_analysis else 'sample'
            }
            
            performance_logger.end_timer('full_csv_analysis')
            return result
            
        except Exception as e:
            analysis_logger.log_error('csv_files_analysis', str(e))
            return {'error': str(e)}
    
    def analyze_card_based_mapping(self, headers_a: List[str], headers_b: List[str],
                                  sample_data_a: List[Dict], sample_data_b: List[Dict],
                                  full_data_a: Optional[List[Dict]] = None,
                                  full_data_b: Optional[List[Dict]] = None) -> Tuple[List[Dict], List[Dict]]:
        """ã‚«ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ"""
        performance_logger.start_timer('card_based_mapping')
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            data_a = full_data_a if full_data_a else sample_data_a
            data_b = full_data_b if full_data_b else sample_data_b
            
            analysis_logger.logger.info(f"åˆ†æãƒ‡ãƒ¼ã‚¿æ•°: Aç¤¾={len(data_a)}, Bç¤¾={len(data_b)}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: åŒã˜ã‚«ãƒ¼ãƒ‰ã‚’ç‰¹å®š
            card_matches = self.card_matcher.find_matching_cards(data_a, data_b, headers_a, headers_b)
            
            if len(card_matches) < self.config.get('min_sample_count', 3):
                analysis_logger.logger.warning("ãƒãƒƒãƒã™ã‚‹ã‚«ãƒ¼ãƒ‰ãŒå°‘ãªã™ãã¾ã™ã€‚å¾“æ¥ã®æ–¹æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                return self.field_mapper.analyze_traditional_mappings(headers_a, headers_b, sample_data_a, sample_data_b)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒƒãƒã—ãŸã‚«ãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œã‚’åˆ†æ
            field_mappings = self.field_mapper.analyze_field_mappings_from_matches(card_matches, headers_a, headers_b)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ä¿¡é ¼åº¦ã‚’è¨ˆç®—
            enhanced_mappings = self.field_mapper.calculate_mapping_confidence(field_mappings, card_matches)
            
            performance_logger.end_timer('card_based_mapping')
            return enhanced_mappings, card_matches
            
        except Exception as e:
            analysis_logger.log_error('card_based_mapping', str(e))
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾“æ¥æ‰‹æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self.field_mapper.analyze_traditional_mappings(headers_a, headers_b, sample_data_a, sample_data_b)
    
    def create_mapping_summary(self, enhanced_mappings: List[Dict], card_matches: List[Dict],
                              analysis_a: Dict, analysis_b: Dict) -> Dict[str, Any]:
        """ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        
        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        high_confidence_mappings = [m for m in enhanced_mappings if m.get('confidence', 0.0) > 0.8]
        medium_confidence_mappings = [m for m in enhanced_mappings if 0.6 < m.get('confidence', 0.0) <= 0.8]
        low_confidence_mappings = [m for m in enhanced_mappings if m.get('confidence', 0.0) <= 0.6]
         
        # ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã®å“è³ªåˆ†æ
        match_quality = self.card_matcher.analyze_match_quality(card_matches)
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ
        field_types = {}
        for mapping in enhanced_mappings:
            field_type = mapping.get('field_type', 'unknown')
            if field_type not in field_types:
                field_types[field_type] = []
            field_types[field_type].append(mapping)
        
        summary = {
            'analysis_summary': {
                'total_fields_a': len(analysis_a['headers']),
                'total_fields_b': len(analysis_b['headers']),
                'total_records_a': analysis_a.get('total_rows', 0),
                'total_records_b': analysis_b.get('total_rows', 0),
                'card_matches_found': len(card_matches),
                'total_mappings_detected': len(enhanced_mappings)
            },
            'mapping_quality': {
                'high_confidence_count': len(high_confidence_mappings),
                'medium_confidence_count': len(medium_confidence_mappings),
                'low_confidence_count': len(enhanced_mappings) - len(high_confidence_mappings) - len(medium_confidence_mappings),
                'average_confidence': sum(m.get('confidence', 0.0) for m in enhanced_mappings) / len(enhanced_mappings) if enhanced_mappings else 0,
                'coverage_ratio_a': len(set(m.get('company_a_field', '') for m in enhanced_mappings if m.get('company_a_field'))) / len(analysis_a['headers']),
                'coverage_ratio_b': len(set(m.get('company_b_field', '') for m in enhanced_mappings if m.get('company_b_field'))) / len(analysis_b['headers'])
            },
            'card_matching_quality': match_quality,
            'field_type_distribution': {
                field_type: len(mappings) for field_type, mappings in field_types.items()
            },
            'recommended_actions': self._generate_recommendations(enhanced_mappings, card_matches, match_quality)
        }
        
        return summary
    
    def export_mapping_rules(self, enhanced_mappings: List[Dict], 
                           confidence_threshold: float = 0.8) -> Dict[str, Any]:
        """ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        rules = self.field_mapper.create_mapping_rules(enhanced_mappings, confidence_threshold)
        
        export_data = {
            'version': '1.0',
            'created_at': None,  # å®Ÿè£…æ™‚ã«ç¾åœ¨æ™‚åˆ»ã‚’è¨­å®š
            'confidence_threshold': confidence_threshold,
            'total_rules': len(rules),
            'rules': rules,
            'metadata': {
                'engine_version': 'Mercury Mapping Engine v2.0',
                'analysis_method': 'card_based_matching',
                'quality_metrics': {
                    'average_confidence': sum(r.get('confidence', 0.0) for r in rules) / len(rules) if rules else 0,
                    'high_quality_rules': len([r for r in rules if r.get('confidence', 0.0) > 0.9])
                }
            }
        }
        
        return export_data
    
    def validate_mapping_results(self, enhanced_mappings: List[Dict], 
                                card_matches: List[Dict]) -> Dict[str, Any]:
        """ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã®æ¤œè¨¼"""
        validation_result = {
            'is_valid': True,
            'issues': [],
            'warnings': [],
            'statistics': {}
        }
        
        # åŸºæœ¬çš„ãªæ¤œè¨¼
        if not enhanced_mappings:
            validation_result['is_valid'] = False
            validation_result['issues'].append("ãƒãƒƒãƒ”ãƒ³ã‚°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return validation_result
        
        if not card_matches:
            validation_result['warnings'].append("ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        a_fields = [m.get('company_a_field', '') for m in enhanced_mappings]
        b_fields = [m.get('company_b_field', '') for m in enhanced_mappings]
        
        duplicate_a = [f for f in set(a_fields) if a_fields.count(f) > 1]
        duplicate_b = [f for f in set(b_fields) if b_fields.count(f) > 1]
        
        if duplicate_a:
            validation_result['warnings'].append(f"Aç¤¾ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®é‡è¤‡: {duplicate_a}")
        
        if duplicate_b:
            validation_result['warnings'].append(f"Bç¤¾ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®é‡è¤‡: {duplicate_b}")
        
        # ä¿¡é ¼åº¦ã®åˆ†å¸ƒãƒã‚§ãƒƒã‚¯
        confidences = [m.get('confidence', 0.0) for m in enhanced_mappings]
        low_confidence_count = len([c for c in confidences if c < 0.5])
        
        if low_confidence_count > len(enhanced_mappings) * 0.5:
            validation_result['warnings'].append("ä½ä¿¡é ¼åº¦ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå…¨ä½“ã®50%ã‚’è¶…ãˆã¦ã„ã¾ã™")
        
        validation_result['statistics'] = {
            'total_mappings': len(enhanced_mappings),
            'unique_a_fields': len(set(a_fields)),
            'unique_b_fields': len(set(b_fields)),
            'average_confidence': sum(confidences) / len(confidences),
            'low_confidence_count': low_confidence_count
        }
        
        return validation_result
    
    def _generate_recommendations(self, enhanced_mappings: List[Dict], 
                                card_matches: List[Dict], match_quality: Dict) -> List[str]:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        recommendations = []
        
        if not enhanced_mappings:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¦å†åˆ†æã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
            return recommendations
        
        high_confidence_count = len([m for m in enhanced_mappings if m.get('confidence', 0.0) > 0.8])
        total_mappings = len(enhanced_mappings)
        
        if high_confidence_count / total_mappings > 0.8:
            recommendations.append("âœ… é«˜å“è³ªãªãƒãƒƒãƒ”ãƒ³ã‚°ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã“ã®ãƒ«ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
        elif high_confidence_count / total_mappings > 0.5:
            recommendations.append("âš ï¸ ä¸­ç¨‹åº¦ã®å“è³ªã§ã™ã€‚é«˜ä¿¡é ¼åº¦ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¿ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        else:
            recommendations.append("âŒ ä½å“è³ªãªãƒãƒƒãƒ”ãƒ³ã‚°ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®è¦‹ç›´ã—ã‚„æ‰‹å‹•ã§ã®ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™")
        
        if len(card_matches) < 10:
            recommendations.append("ğŸ” ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒæ•°ãŒå°‘ãªã„ã§ã™ã€‚ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã§ã®å†åˆ†æã‚’æ¨å¥¨ã—ã¾ã™")
        
        if match_quality.get('average_score', 0) < 0.8:
            recommendations.append("ğŸ“ ã‚«ãƒ¼ãƒ‰åã®æ­£è¦åŒ–ã‚„ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        
        return recommendations
