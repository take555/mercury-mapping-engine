def brute_force_matching(self, data_a: List[Dict], data_b: List[Dict], 
                           headers_a: List[str], headers_b: List[str],
                           max_sample_size: int = 100,
                           similarity_mode: str = 'library',  # 'library' or 'ai'
                           ai_manager=None) -> List[Dict[str, Any]]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åŠ›æŠ€ãƒãƒƒãƒãƒ³ã‚°: ãƒ©ã‚¤ãƒ–ãƒ©ãƒª vs AI ã§é¡ä¼¼åº¦è¨ˆç®—ã‚’åˆ‡ã‚Šæ›¿ãˆ
        
        Args:
            data_a: Aç¤¾ãƒ‡ãƒ¼ã‚¿
            data_b: Bç¤¾ãƒ‡ãƒ¼ã‚¿  
            headers_a: Aç¤¾ãƒ˜ãƒƒãƒ€ãƒ¼
            headers_b: Bç¤¾ãƒ˜ãƒƒãƒ€ãƒ¼
            max_sample_size: æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
            similarity_mode: 'library' (Python libs) or 'ai' (Claude API)
            ai_manager: AI Manager instance (similarity_mode='ai'æ™‚ã«å¿…è¦)
        
        Returns:
            é«˜ç²¾åº¦ãƒãƒƒãƒãƒ³ã‚°çµæœ
        """
        performance_logger.start_timer('brute_force_matching')
        
        mode_info = {
            'library': 'ğŸ Python Library Mode - é«˜é€Ÿãƒ»å®‰ä¾¡',
            'ai': 'ğŸ¤– Claude AI Mode - é«˜ç²¾åº¦ãƒ»æ„å‘³ç†è§£'
        }
        
        analysis_logger.logger.info(f"ğŸ”¥ Brute Force Matching é–‹å§‹ - {mode_info.get(similarity_mode, similarity_mode)}")
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        sample_a = data_a[:max_sample_size]
        sample_b = data_b[:max_sample_size]
        
        matches = []
        field_correlation_matrix = {}
        
        analysis_logger.logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: Aç¤¾{len(sample_a)}è¡Œ Ã— Bç¤¾{len(sample_b)}è¡Œ")
        analysis_logger.logger.info(f"âš™ï¸ é¡ä¼¼åº¦è¨ˆç®—ãƒ¢ãƒ¼ãƒ‰: {similarity_mode}")
        
        for i, row_a in enumerate(sample_a):
            best_matches = []
            
            for j, row_b in enumerate(sample_b):
                # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ
                if similarity_mode == 'library':
                    field_match_results = self._compare_all_fields_library(
                        row_a, row_b, headers_a, headers_b
                    )
                elif similarity_mode == 'ai':
                    field_match_results = self._compare_all_fields_ai(
                        row_a, row_b, headers_a, headers_b, ai_manager
                    )
                else:
                    raise ValueError(f"Unknown similarity_mode: {similarity_mode}")
                
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œãƒãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                self._update_field_correlation_matrix(
                    field_correlation_matrix, field_match_results
                )
                
                # è¡Œå…¨ä½“ã®ãƒãƒƒãƒã‚¹ã‚³ã‚¢è¨ˆç®—
                total_score = self._calculate_brute_force_score(field_match_results)
                
                if total_score > 0.6:
                    best_matches.append({
                        'row_a_index': i,
                        'row_b_index': j,
                        'row_a_data': row_a,
                        'row_b_data': row_b,
                        'match_score': total_score,
                        'field_matches': field_match_results,
                        'similarity_mode': similarity_mode,
                        'match_details': {
                            'matched_fields_count': len([fm for fm in field_match_results if fm['similarity'] > 0.7]),
                            'total_fields_compared': len(field_match_results),
                            'best_field_match': max(field_match_results, key=lambda x: x['similarity']) if field_match_results else None
                        }
                    })
            
            # å„Aç¤¾è¡Œã«å¯¾ã—ã¦æœ€è‰¯ã®ãƒãƒƒãƒã®ã¿ä¿æŒ
            if best_matches:
                best_match = max(best_matches, key=lambda x: x['match_score'])
                matches.append(best_match)
        
        # é‡è¤‡é™¤å»
        unique_matches = self._remove_duplicate_matches_brute_force(matches)
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œçµ±è¨ˆ
        field_mapping_stats = self._analyze_field_correlations(field_correlation_matrix)
        
        analysis_logger.logger.info(f"ğŸ¯ Brute Forceçµæœ: {len(unique_matches)}ä»¶ã®ãƒãƒƒãƒ")
        analysis_logger.logger.info(f"ğŸ“ˆ ç™ºè¦‹ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œ: {len(field_mapping_stats)}çµ„")
        
        # çµæœã«ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’è¿½åŠ 
        for match in unique_matches:
            match['discovered_field_mappings'] = field_mapping_stats
            match['analysis_mode'] = similarity_mode
        
        performance_logger.end_timer('brute_force_matching')
        return unique_matches

    def _compare_all_fields_library(self, row_a: Dict, row_b: Dict, 
                                   headers_a: List[str], headers_b: List[str]) -> List[Dict]:
        """ğŸ Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ™ãƒ¼ã‚¹ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ"""
        field_matches = []
        
        for field_a in headers_a:
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a or len(value_a) < 2:
                continue
                
            for field_b in headers_b:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b or len(value_b) < 2:
                    continue
                
                # è¤‡æ•°æ‰‹æ³•ã§å¾¹åº•æ¯”è¼ƒ
                similarities = self._calculate_comprehensive_similarity(value_a, value_b)
                max_similarity = max(similarities.values())
                
                if max_similarity > 0.5:
                    field_matches.append({
                        'field_a': field_a,
                        'field_b': field_b,
                        'value_a': value_a,
                        'value_b': value_b,
                        'similarity': max_similarity,
                        'similarity_details': similarities,
                        'match_type': self._classify_match_type(value_a, value_b, similarities),
                        'calculation_method': 'library'
                    })
        
        return field_matches

    def _compare_all_fields_ai(self, row_a: Dict, row_b: Dict, 
                              headers_a: List[str], headers_b: List[str], 
                              ai_manager) -> List[Dict]:
        """ğŸ¤– Claude AIãƒ™ãƒ¼ã‚¹ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¯”è¼ƒ"""
        if not ai_manager:
            analysis_logger.logger.warning("AI Manager not provided, falling back to library mode")
            return self._compare_all_fields_library(row_a, row_b, headers_a, headers_b)
        
        field_matches = []
        
        # ãƒãƒƒãƒå‡¦ç†ã§AIåˆ†æï¼ˆåŠ¹ç‡åŒ–ï¼‰
        field_pairs = []
        for field_a in headers_a:
            value_a = str(row_a.get(field_a, '')).strip()
            if not value_a or len(value_a) < 2:
                continue
                
            for field_b in headers_b:
                value_b = str(row_b.get(field_b, '')).strip()
                if not value_b or len(value_b) < 2:
                    continue
                
                field_pairs.append({
                    'field_a': field_a,
                    'field_b': field_b,
                    'value_a': value_a,
                    'value_b': value_b
                })
        
        # AIåˆ†æå®Ÿè¡Œ
        if field_pairs:
            ai_results = self._batch_ai_similarity_analysis(field_pairs, ai_manager)
            
            for i, pair in enumerate(field_pairs):
                ai_result = ai_results.get(i, {})
                similarity = ai_result.get('similarity', 0.0)
                
                if similarity > 0.5:
                    field_matches.append({
                        'field_a': pair['field_a'],
                        'field_b': pair['field_b'],
                        'value_a': pair['value_a'],
                        'value_b': pair['value_b'],
                        'similarity': similarity,
                        'ai_reasoning': ai_result.get('reasoning', ''),
                        'match_type': ai_result.get('match_type', 'ai_determined'),
                        'calculation_method': 'ai',
                        'ai_confidence': ai_result.get('confidence', similarity)
                    })
        
        return field_matches

    def _batch_ai_similarity_analysis(self, field_pairs: List[Dict], ai_manager) -> Dict:
        """ãƒãƒƒãƒã§AIé¡ä¼¼åº¦åˆ†æå®Ÿè¡Œ"""
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            prompt = self._build_similarity_analysis_prompt(field_pairs)
            
            # Claude APIå‘¼ã³å‡ºã—
            result = ai_manager.claude_client.call_api(
                prompt, 
                model='claude-3-haiku-20240307'  # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ã§åŠ¹ç‡åŒ–
            )
            
            if result['success']:
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
                return self._parse_ai_similarity_response(result['content'])
            else:
                analysis_logger.logger.error(f"AI similarity analysis failed: {result.get('error')}")
                return {}
                
        except Exception as e:
            analysis_logger.logger.error(f"AI similarity analysis error: {e}")
            return {}

    def _build_similarity_analysis_prompt(self, field_pairs: List[Dict]) -> str:
        """AIé¡ä¼¼åº¦åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        pairs_text = ""
        for i, pair in enumerate(field_pairs[:20]):  # æœ€å¤§20ãƒšã‚¢ãšã¤å‡¦ç†
            pairs_text += f"""
{i}: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å "{pair['field_a']}" vs "{pair['field_b']}"
    å€¤ã®ä¾‹: "{pair['value_a']}" vs "{pair['value_b']}"
"""
        
        prompt = f"""
ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒšã‚¢ã«ã¤ã„ã¦ã€é¡ä¼¼åº¦ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ã€‘
{pairs_text}

ã€åˆ¤å®šåŸºæº–ã€‘
1. æ„å‘³çš„é¡ä¼¼æ€§ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®æ„å‘³ï¼‰
2. ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ä¸€è‡´åº¦
3. ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã®æ•´åˆæ€§
4. å€¤ã®å†…å®¹ã®é¡ä¼¼æ€§

ã€å›ç­”å½¢å¼ã€‘
JSONå½¢å¼ã§å„ãƒšã‚¢ã®åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{{
  "0": {{
    "similarity": 0.85,
    "reasoning": "attackã¨APã¯ä¸¡æ–¹ã¨ã‚‚æ”»æ’ƒåŠ›ã‚’è¡¨ã—ã€æ•°å€¤ã‚‚ä¸€è‡´",
    "match_type": "semantic_match",
    "confidence": 0.9
  }},
  "1": {{ ... }}
}}

é¡ä¼¼åº¦ã¯0.0-1.0ã§è©•ä¾¡ã—ã€0.7ä»¥ä¸Šã‚’é«˜é¡ä¼¼åº¦ã¨ã—ã¦åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
"""
        return prompt

    def _parse_ai_similarity_response(self, content: str) -> Dict:
        """AIå¿œç­”ã®JSONãƒ‘ãƒ¼ã‚¹"""
        try:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                import json
                return json.loads(json_match.group())
            else:
                analysis_logger.logger.warning("AI response does not contain valid JSON")
                return {}
        except Exception as e:
            analysis_logger.logger.error(f"Failed to parse AI response: {e}")
            return {}

    # æ—¢å­˜ã®_calculate_comprehensive_similarityç­‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãã®ã¾ã¾ä¿æŒ