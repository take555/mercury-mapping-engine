"""
2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®š
Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ
"""

import logging
from collections import defaultdict

def two_stage_matching_system(data_a, data_b, headers_a, headers_b):
    """åŠ¹ç‡çš„ãª2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    logger = logging.getLogger('two_stage_matching')
    
    # ========================================
    # Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®š
    # ========================================
    logger.info("ğŸ¯ Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®šé–‹å§‹")
    
    # ã‚­ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®š
    key_fields = identify_key_fields(headers_a, headers_b)
    logger.info(f"ç‰¹å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {key_fields}")
    
    # åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‚’ç‰¹å®š
    identical_card_pairs = find_identical_cards(data_a, data_b, key_fields)
    logger.info(f"âœ… Stage 1å®Œäº†: {len(identical_card_pairs)}çµ„ã®åŒä¸€ã‚«ãƒ¼ãƒ‰ã‚’ç‰¹å®š")
    
    # ========================================
    # Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ
    # ========================================
    logger.info("ğŸ”— Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æé–‹å§‹")
    
    if not identical_card_pairs:
        logger.warning("åŒä¸€ã‚«ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return [], []
    
    # åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å­¦ç¿’
    field_mappings = analyze_field_mappings_from_pairs(identical_card_pairs, headers_a, headers_b)
    logger.info(f"âœ… Stage 2å®Œäº†: {len(field_mappings)}ä»¶ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ¤œå‡º")
    
    return identical_card_pairs, field_mappings

def identify_key_fields(headers_a, headers_b):
    """é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®š"""
    
    # é‡è¦åº¦ã®é«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    key_patterns = {
        'name': ['name', 'åå‰', 'ã‚«ãƒ¼ãƒ‰å', 'å•†å“å', 'title'],
        'id': ['id', 'serial', 'å‹ç•ª', 'code', 'number', 'jan'],
        'date': ['date', 'æ—¥ä»˜', 'ç™ºå£²æ—¥', 'release', 'publish']
    }
    
    key_fields = {'a': {}, 'b': {}}
    
    # Aç¤¾ã®ã‚­ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç‰¹å®š
    for header in headers_a:
        header_lower = header.lower()
        for key_type, patterns in key_patterns.items():
            if any(pattern in header_lower for pattern in patterns):
                if key_type not in key_fields['a']:
                    key_fields['a'][key_type] = []
                key_fields['a'][key_type].append(header)
    
    # Bç¤¾ã®ã‚­ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç‰¹å®š
    for header in headers_b:
        header_lower = header.lower()
        for key_type, patterns in key_patterns.items():
            if any(pattern in header_lower for pattern in patterns):
                if key_type not in key_fields['b']:
                    key_fields['b'][key_type] = []
                key_fields['b'][key_type].append(header)
    
    return key_fields

def find_identical_cards(data_a, data_b, key_fields):
    """åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‚’ç‰¹å®š"""
    
    def normalize_value(value, field_type):
        """å€¤ã®æ­£è¦åŒ–"""
        if not value:
            return ""
        
        value = str(value).strip().replace('\ufeff', '')
        
        if field_type == 'date':
            # æ—¥ä»˜ã®æ­£è¦åŒ–: 2024/1/24 â†’ 20240124
            if '/' in value:
                parts = value.split('/')
                if len(parts) == 3:
                    year, month, day = parts
                    return f"{year.zfill(4)}{month.zfill(2)}{day.zfill(2)}"
            return value.replace('-', '').replace('/', '')
        
        elif field_type == 'name':
            # åå‰ã®æ­£è¦åŒ–
            return value.replace('ï¼†', '&').replace('ã€€', ' ').lower().strip()
        
        elif field_type == 'id':
            # IDã®æ­£è¦åŒ–
            return value.upper().strip()
        
        return value.lower().strip()
    
    def calculate_match_score(card_a, card_b):
        """ã‚«ãƒ¼ãƒ‰é–“ã®ãƒãƒƒãƒã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0.0
        matches = []
        
        # å„ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—ã§ã®ãƒãƒƒãƒãƒ³ã‚°ç¢ºèª
        for key_type in ['name', 'id', 'date']:
            fields_a = key_fields.get('a', {}).get(key_type, [])
            fields_b = key_fields.get('b', {}).get(key_type, [])
            
            for field_a in fields_a:
                for field_b in fields_b:
                    val_a = normalize_value(card_a.get(field_a), key_type)
                    val_b = normalize_value(card_b.get(field_b), key_type)
                    
                    if val_a and val_b and val_a == val_b:
                        # é‡è¦åº¦ã«å¿œã˜ã¦ã‚¹ã‚³ã‚¢åŠ ç®—
                        if key_type == 'name':
                            score += 0.5  # åå‰ã¯50ç‚¹
                        elif key_type == 'id':
                            score += 0.4   # IDã¯40ç‚¹
                        elif key_type == 'date':
                            score += 0.1   # æ—¥ä»˜ã¯10ç‚¹
                        
                        matches.append({
                            'type': key_type,
                            'field_a': field_a,
                            'field_b': field_b,
                            'value_a': val_a,
                            'value_b': val_b
                        })
        
        return score, matches
    
    # å®Ÿéš›ã®ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
    identical_pairs = []
    
    for card_a in data_a:
        for card_b in data_b:
            score, match_details = calculate_match_score(card_a, card_b)
            
            # ã‚¹ã‚³ã‚¢0.8ä»¥ä¸Šã‚’åŒä¸€ã‚«ãƒ¼ãƒ‰ã¨ã—ã¦åˆ¤å®š
            if score >= 0.8:
                identical_pairs.append({
                    'card_a': card_a,
                    'card_b': card_b,
                    'match_score': round(score, 3),
                    'match_details': match_details
                })
    
    return identical_pairs

def analyze_field_mappings_from_pairs(identical_pairs, headers_a, headers_b):
    """åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’åˆ†æ"""
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é›†è¨ˆ
    field_match_stats = defaultdict(lambda: {
        'exact_matches': 0,
        'total_comparisons': 0,
        'sample_pairs': []
    })
    
    for pair in identical_pairs:
        card_a = pair['card_a']
        card_b = pair['card_b']
        
        # å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåŒä¸€ã‚«ãƒ¼ãƒ‰ãªã®ã§åŠ¹ç‡çš„ï¼‰
        for field_a in headers_a:
            for field_b in headers_b:
                val_a = str(card_a.get(field_a, '')).strip()
                val_b = str(card_b.get(field_b, '')).strip()
                
                field_pair = f"{field_a}â†’{field_b}"
                stats = field_match_stats[field_pair]
                
                stats['total_comparisons'] += 1
                
                # å€¤ãŒä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if val_a and val_b and normalize_for_comparison(val_a) == normalize_for_comparison(val_b):
                    stats['exact_matches'] += 1
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒšã‚¢ã‚’ä¿å­˜
                    if len(stats['sample_pairs']) < 3:
                        stats['sample_pairs'].append({
                            'value_a': val_a,
                            'value_b': val_b,
                            'card_a_key': card_a.get('name', ''),
                            'card_b_key': card_b.get('ã‚«ãƒ¼ãƒ‰å', '')
                        })
    
    # ä¿¡é ¼åº¦ã®é«˜ã„ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¿ã‚’æŠ½å‡º
    field_mappings = []
    
    for field_pair, stats in field_match_stats.items():
        if stats['total_comparisons'] > 0:
            confidence = stats['exact_matches'] / stats['total_comparisons']
            
            # ä¿¡é ¼åº¦50%ä»¥ä¸Šã®ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¿æ¡ç”¨
            if confidence >= 0.5:
                field_a, field_b = field_pair.split('â†’')
                
                field_mappings.append({
                    'field_a': field_a,
                    'field_b': field_b,
                    'confidence': round(confidence, 3),
                    'sample_count': stats['exact_matches'],
                    'total_comparisons': stats['total_comparisons'],
                    'field_type': 'learned_from_identical_cards',
                    'quality_score': 'High' if confidence > 0.8 else 'Medium',
                    'sample_pairs': stats['sample_pairs']
                })
    
    # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    field_mappings.sort(key=lambda x: x['confidence'], reverse=True)
    
    return field_mappings

def normalize_for_comparison(value):
    """æ¯”è¼ƒç”¨ã®å€¤æ­£è¦åŒ–"""
    if not value:
        return ""
    
    value = str(value).strip().replace('\ufeff', '')
    # æ—¥ä»˜æ­£è¦åŒ–
    if '/' in value and len(value.split('/')) == 3:
        parts = value.split('/')
        if len(parts) == 3 and all(p.isdigit() for p in parts):
            year, month, day = parts
            return f"{year.zfill(4)}{month.zfill(2)}{day.zfill(2)}"
    
    # ä¸€èˆ¬çš„ãªæ­£è¦åŒ–
    return value.replace('ï¼†', '&').replace('ã€€', ' ').lower().strip()

def format_results_for_display(identical_pairs, field_mappings):
    """çµæœã‚’è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    
    # åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã®ã‚µãƒãƒªãƒ¼
    card_summary = []
    for i, pair in enumerate(identical_pairs[:10]):  # ä¸Šä½10ä»¶
        card_a = pair['card_a']
        card_b = pair['card_b']
        
        name_a = card_a.get('name', card_a.get('serial', 'Unknown'))
        name_b = card_b.get('ã‚«ãƒ¼ãƒ‰å', card_b.get('å‹ç•ª', 'Unknown'))
        
        card_summary.append({
            'index': i + 1,
            'name_a': name_a,
            'name_b': name_b,
            'match_score': pair['match_score'],
            'match_types': [detail['type'] for detail in pair['match_details']]
        })
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã‚µãƒãƒªãƒ¼
    mapping_summary = []
    for mapping in field_mappings[:20]:  # ä¸Šä½20ä»¶
        mapping_summary.append({
            'field_a': mapping['field_a'],
            'field_b': mapping['field_b'],
            'confidence': mapping['confidence'],
            'sample_count': mapping['sample_count'],
            'quality': mapping['quality_score']
        })
    
    return {
        'identical_cards': card_summary,
        'field_mappings': mapping_summary,
        'statistics': {
            'total_identical_cards': len(identical_pairs),
            'total_field_mappings': len(field_mappings),
            'high_confidence_mappings': len([m for m in field_mappings if m['confidence'] > 0.8])
        }
    }

# enhanced.pyã«çµ±åˆã™ã‚‹ãŸã‚ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
def enhanced_two_stage_matching(data_a, data_b, headers_a, headers_b):
    """enhanced.pyç”¨ã®2æ®µéšãƒãƒƒãƒãƒ³ã‚°"""
    
    # 2æ®µéšãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
    identical_pairs, field_mappings = two_stage_matching_system(
        data_a, data_b, headers_a, headers_b
    )
    
    # enhanced.pyã®æ—¢å­˜å½¢å¼ã«åˆã‚ã›ã¦çµæœã‚’å¤‰æ›
    matches = []
    for pair in identical_pairs:
        matches.append({
            'card_a': pair['card_a'],
            'card_b': pair['card_b'],
            'overall_similarity': pair['match_score'],
            'similarity_details': {
                f"{detail['field_a']}â†’{detail['field_b']}": 1.0
                for detail in pair['match_details']
            }
        })
    
    return matches, field_mappings