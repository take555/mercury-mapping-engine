# ===============================================
# Mercury Mapping Engine - 2æ®µéšãƒãƒƒãƒãƒ³ã‚°å®Ÿè£…
# ===============================================

import time
import logging
from collections import defaultdict
import re

# ===============================================
# Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®šã‚·ã‚¹ãƒ†ãƒ 
# ===============================================

def identify_key_fields(headers_a, headers_b):
    """é‡è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•ç‰¹å®š"""
    key_patterns = {
        'name': ['name', 'åå‰', 'ã‚«ãƒ¼ãƒ‰å', 'å•†å“å', 'title', 'product'],
        'id': ['id', 'serial', 'å‹ç•ª', 'code', 'number', 'jan', 'sku'],
        'date': ['date', 'æ—¥ä»˜', 'ç™ºå£²æ—¥', 'release', 'publish', 'launch']
    }
    
    key_fields = {'a': {}, 'b': {}}
    
    for header in headers_a:
        header_lower = header.lower()
        for key_type, patterns in key_patterns.items():
            if any(pattern in header_lower for pattern in patterns):
                if key_type not in key_fields['a']:
                    key_fields['a'][key_type] = []
                key_fields['a'][key_type].append(header)
    
    for header in headers_b:
        header_lower = header.lower()
        for key_type, patterns in key_patterns.items():
            if any(pattern in header_lower for pattern in patterns):
                if key_type not in key_fields['b']:
                    key_fields['b'][key_type] = []
                key_fields['b'][key_type].append(header)
    
    return key_fields

def normalize_value(value, field_type):
    """å€¤ã®æ­£è¦åŒ–å‡¦ç†"""
    if not value:
        return ""
    
    value = str(value).strip().replace('\ufeff', '')
    
    if field_type == 'date':
        # æ—¥ä»˜ã®æ­£è¦åŒ–: 2024/1/24 â†’ 20240124
        if '/' in value:
            parts = value.split('/')
            if len(parts) == 3 and all(p.isdigit() for p in parts):
                year, month, day = parts
                return f"{year.zfill(4)}{month.zfill(2)}{day.zfill(2)}"
        return value.replace('-', '').replace('/', '').replace(' ', '')
    
    elif field_type == 'name':
        # åå‰ã®æ­£è¦åŒ–: è¨˜å·çµ±ä¸€ã€å¤§å°æ–‡å­—çµ±ä¸€
        return value.replace('ï¼†', '&').replace('ã€€', ' ').lower().strip()
    
    elif field_type == 'id':
        # IDã®æ­£è¦åŒ–: å¤§æ–‡å­—çµ±ä¸€ã€ç©ºç™½é™¤å»
        return value.upper().strip().replace(' ', '')
    
    return value.lower().strip()

def find_identical_cards(data_a, data_b, key_fields):
    """åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‚’ç‰¹å®š"""
    logger = logging.getLogger('identical_cards')
    
    def calculate_match_score(card_a, card_b):
        """ã‚«ãƒ¼ãƒ‰é–“ã®ãƒãƒƒãƒã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0.0
        matches = []
        
        # å„ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—ã§ã®ãƒãƒƒãƒãƒ³ã‚°ç¢ºèª
        for key_type in ['name', 'id', 'date']:
            fields_a = key_fields.get('a', {}).get(key_type, [])
            fields_b = key_fields.get('b', {}).get(key_type, [])
            
            for field_a in fields_a:
                for field_b in fields_b:
                    val_a = normalize_value(card_a.get(field_a), key_type)
                    val_b = normalize_value(card_b.get(field_b), key_type)
                    
                    if val_a and val_b and val_a == val_b:
                        # é‡è¦åº¦ã«å¿œã˜ã¦ã‚¹ã‚³ã‚¢åŠ ç®—
                        if key_type == 'name':
                            score += 0.5  # åå‰ã¯50ç‚¹
                        elif key_type == 'id':
                            score += 0.4   # IDã¯40ç‚¹
                        elif key_type == 'date':
                            score += 0.1   # æ—¥ä»˜ã¯10ç‚¹
                        
                        matches.append({
                            'type': key_type,
                            'field_a': field_a,
                            'field_b': field_b,
                            'value': val_a
                        })
                        break  # åŒã‚¿ã‚¤ãƒ—ã§è¤‡æ•°ãƒãƒƒãƒã—ã¦ã‚‚1å›ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
        
        return score, matches
    
    # å®Ÿéš›ã®ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
    identical_pairs = []
    logger.info(f"åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®šé–‹å§‹: {len(data_a)}Ã—{len(data_b)}è¡Œ")
    
    for card_a in data_a:
        for card_b in data_b:
            score, match_details = calculate_match_score(card_a, card_b)
            
            # ã‚¹ã‚³ã‚¢0.8ä»¥ä¸Šã‚’åŒä¸€ã‚«ãƒ¼ãƒ‰ã¨ã—ã¦åˆ¤å®š
            if score >= 0.8:
                identical_pairs.append({
                    'card_a': card_a,
                    'card_b': card_b,
                    'match_score': round(score, 3),
                    'match_details': match_details
                })
    
    logger.info(f"åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®šå®Œäº†: {len(identical_pairs)}çµ„")
    return identical_pairs

# ===============================================
# Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
# ===============================================

def analyze_field_mappings_from_pairs(identical_pairs, headers_a, headers_b):
    """åŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å­¦ç¿’"""
    logger = logging.getLogger('field_mapping')
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é›†è¨ˆ
    field_match_stats = defaultdict(lambda: {
        'exact_matches': 0,
        'total_comparisons': 0,
        'sample_values': []
    })
    
    logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å­¦ç¿’é–‹å§‹: {len(identical_pairs)}çµ„ã®ãƒšã‚¢")
    
    for pair in identical_pairs:
        card_a = pair['card_a']
        card_b = pair['card_b']
        
        # å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåŒä¸€ã‚«ãƒ¼ãƒ‰ãƒšã‚¢ãªã®ã§åŠ¹ç‡çš„ï¼‰
        for field_a in headers_a:
            for field_b in headers_b:
                val_a = str(card_a.get(field_a, '')).strip()
                val_b = str(card_b.get(field_b, '')).strip()
                
                field_pair = f"{field_a}â†’{field_b}"
                stats = field_match_stats[field_pair]
                
                stats['total_comparisons'] += 1
                
                # å€¤ãŒä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæ­£è¦åŒ–å¾Œï¼‰
                if val_a and val_b:
                    val_a_norm = normalize_for_comparison(val_a)
                    val_b_norm = normalize_for_comparison(val_b)
                    
                    if val_a_norm == val_b_norm:
                        stats['exact_matches'] += 1
                        
                        # ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’ä¿å­˜
                        if len(stats['sample_values']) < 3:
                            stats['sample_values'].append({
                                'original_a': val_a,
                                'original_b': val_b,
                                'normalized': val_a_norm
                            })
    
    # ä¿¡é ¼åº¦ã®é«˜ã„ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¿ã‚’æŠ½å‡º
    field_mappings = []
    
    for field_pair, stats in field_match_stats.items():
        if stats['total_comparisons'] > 0:
            confidence = stats['exact_matches'] / stats['total_comparisons']
            
            # ä¿¡é ¼åº¦50%ä»¥ä¸Šã®ãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¿æ¡ç”¨
            if confidence >= 0.5:
                field_a, field_b = field_pair.split('â†’')
                
                field_mappings.append({
                    'field_a': field_a.replace('\ufeff', '').strip(),
                    'field_b': field_b.replace('\ufeff', '').strip(),
                    'confidence': round(confidence, 3),
                    'sample_count': stats['exact_matches'],
                    'total_comparisons': stats['total_comparisons'],
                    'field_type': 'learned_from_identical_cards',
                    'quality_score': 'High' if confidence > 0.8 else 'Medium',
                    'sample_values': stats['sample_values']
                })
    
    # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    field_mappings.sort(key=lambda x: x['confidence'], reverse=True)
    
    logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å­¦ç¿’å®Œäº†: {len(field_mappings)}ä»¶")
    return field_mappings

def normalize_for_comparison(value):
    """æ¯”è¼ƒç”¨ã®å€¤æ­£è¦åŒ–"""
    if not value:
        return ""
    
    value = str(value).strip().replace('\ufeff', '')
    
    # æ—¥ä»˜æ­£è¦åŒ–
    if '/' in value and len(value.split('/')) == 3:
        parts = value.split('/')
        if len(parts) == 3 and all(p.isdigit() for p in parts):
            year, month, day = parts
            return f"{year.zfill(4)}{month.zfill(2)}{day.zfill(2)}"
    
    # ä¸€èˆ¬çš„ãªæ­£è¦åŒ–
    return value.replace('ï¼†', '&').replace('ã€€', ' ').lower().strip()

# ===============================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼š2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
# ===============================================

def two_stage_matching_system(data_a, data_b, headers_a, headers_b):
    """åŠ¹ç‡çš„ãª2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    logger = logging.getLogger('two_stage_matching')
    start_time = time.time()
    
    logger.info("=" * 50)
    logger.info("ğŸš€ 2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    logger.info("=" * 50)
    
    # Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®š
    logger.info("ğŸ¯ Stage 1: åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®š")
    stage1_start = time.time()
    
    key_fields = identify_key_fields(headers_a, headers_b)
    logger.info(f"ç‰¹å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {key_fields}")
    
    identical_pairs = find_identical_cards(data_a, data_b, key_fields)
    
    stage1_time = time.time() - stage1_start
    logger.info(f"âœ… Stage 1å®Œäº†: {len(identical_pairs)}çµ„ ({stage1_time:.2f}ç§’)")
    
    if not identical_pairs:
        logger.warning("åŒä¸€ã‚«ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å¾“æ¥ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        return [], []
    
    # Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ
    logger.info("ğŸ”— Stage 2: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æ")
    stage2_start = time.time()
    
    field_mappings = analyze_field_mappings_from_pairs(identical_pairs, headers_a, headers_b)
    
    stage2_time = time.time() - stage2_start
    logger.info(f"âœ… Stage 2å®Œäº†: {len(field_mappings)}ä»¶ ({stage2_time:.2f}ç§’)")
    
    # çµæœã‚µãƒãƒªãƒ¼
    total_time = time.time() - start_time
    logger.info("=" * 50)
    logger.info(f"ğŸ 2æ®µéšãƒãƒƒãƒãƒ³ã‚°å®Œäº†: {total_time:.2f}ç§’")
    logger.info(f"ğŸ“Š çµæœã‚µãƒãƒªãƒ¼:")
    logger.info(f"   - åŒä¸€ã‚«ãƒ¼ãƒ‰: {len(identical_pairs)}çµ„")
    logger.info(f"   - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°: {len(field_mappings)}ä»¶")
    logger.info(f"   - é«˜ä¿¡é ¼åº¦ãƒãƒƒãƒ”ãƒ³ã‚°: {len([m for m in field_mappings if m['confidence'] > 0.8])}ä»¶")
    logger.info("=" * 50)
    
    return identical_pairs, field_mappings

# ===============================================
# enhanced.pyçµ±åˆç”¨ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
# ===============================================

def enhanced_two_stage_matching(data_a, data_b, headers_a, headers_b, max_sample_size=100):
    """enhanced.pyç”¨ã®2æ®µéšãƒãƒƒãƒãƒ³ã‚°"""
    logger = logging.getLogger('enhanced_matching')
    
    # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¶é™
    if len(data_a) > max_sample_size:
        data_a = data_a[:max_sample_size]
        logger.info(f"Aç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’{max_sample_size}ä»¶ã«åˆ¶é™")
    
    if len(data_b) > max_sample_size:
        data_b = data_b[:max_sample_size]
        logger.info(f"Bç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’{max_sample_size}ä»¶ã«åˆ¶é™")
    
    # 2æ®µéšãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
    identical_pairs, field_mappings = two_stage_matching_system(
        data_a, data_b, headers_a, headers_b
    )
    
    # enhanced.pyã®æ—¢å­˜å½¢å¼ã«åˆã‚ã›ã¦çµæœã‚’å¤‰æ›
    matches = []
    for pair in identical_pairs:
        similarity_details = {}
        for detail in pair['match_details']:
            field_pair = f"{detail['field_a']}â†’{detail['field_b']}"
            similarity_details[field_pair] = 1.0
        
        matches.append({
            'card_a': pair['card_a'],
            'card_b': pair['card_b'],
            'overall_similarity': pair['match_score'],
            'similarity_details': similarity_details
        })
    
    return matches, field_mappings

# ===============================================
# é«˜é€ŸHTMLç”Ÿæˆ
# ===============================================

def generate_optimized_html(analysis_a, analysis_b, enhanced_mappings, matches, similarity_mode='library'):
    """æœ€é©åŒ–ã•ã‚ŒãŸHTMLç”Ÿæˆ"""
    start_time = time.time()
    logger = logging.getLogger('html_generation')
    
    # è¡¨ç¤ºä»¶æ•°åˆ¶é™
    display_mappings = enhanced_mappings[:20] if enhanced_mappings else []
    display_matches = matches[:10] if matches else []
    
    html = f"""
<!DOCTYPE html>
<html>
<head>
    <title>ğŸ¯ åˆ†æçµæœ - Mercury Mapping Engine</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 12px; }}
        .header {{ background: linear-gradient(135deg, #4CAF50, #45a049); color: white; padding: 25px; border-radius: 8px; margin-bottom: 30px; }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin: 25px 0; }}
        .stat-card {{ background: #f8f9fa; padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}
        .metric-value {{ font-size: 2.5em; font-weight: bold; color: #4CAF50; }}
        .metric-label {{ font-size: 0.9em; color: #666; margin-top: 8px; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background-color: #f0f0f0; font-weight: bold; }}
        .confidence-high {{ color: #4caf50; font-weight: bold; }}
        .confidence-medium {{ color: #ff9800; font-weight: bold; }}
        .confidence-low {{ color: #f44336; font-weight: bold; }}
        .success {{ background: #e8f5e8; padding: 20px; border-radius: 8px; border-left: 5px solid #4caf50; margin: 20px 0; }}
        .nav-links {{ margin: 30px 0; text-align: center; }}
        .nav-links a {{ margin: 0 10px; padding: 12px 24px; background: #2196f3; color: white; text-decoration: none; border-radius: 6px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¯ é«˜ç²¾åº¦åˆ†æçµæœ (æœ€é©åŒ–ç‰ˆ)</h1>
            <p>Mercury Mapping Engine v2.0 - {similarity_mode.upper()} Mode | 2æ®µéšãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ </p>
        </div>
        
        <div class="success">
            <h3>âœ… åˆ†ææˆåŠŸ - åŠ‡çš„æ€§èƒ½æ”¹å–„</h3>
            <p><strong>åŒä¸€ã‚«ãƒ¼ãƒ‰ç‰¹å®š:</strong> {len(matches)}çµ„</p>
            <p><strong>ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°:</strong> {len(enhanced_mappings)}ä»¶ (ä¿¡é ¼åº¦0.5ä»¥ä¸Š)</p>
            <p><strong>é«˜ä¿¡é ¼åº¦ãƒãƒƒãƒ”ãƒ³ã‚°:</strong> {len([m for m in enhanced_mappings if m.get('confidence', 0) > 0.8])}ä»¶</p>
        </div>
        
        <h2>ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦</h2>
        <div class="stats-grid">
            <div class="stat-card">
                <div class="metric-value">{analysis_a['total_rows']}</div>
                <div class="metric-label">Aç¤¾ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°</div>
            </div>
            <div class="stat-card">
                <div class="metric-value">{analysis_b['total_rows']}</div>
                <div class="metric-label">Bç¤¾ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°</div>
            </div>
            <div class="stat-card">
                <div class="metric-value">{len(matches)}</div>
                <div class="metric-label">åŒä¸€ã‚«ãƒ¼ãƒ‰çµ„</div>
            </div>
            <div class="stat-card">
                <div class="metric-value">{len(enhanced_mappings)}</div>
                <div class="metric-label">ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°</div>
            </div>
        </div>
    """
    
    # åŒä¸€ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
    if display_matches:
        html += """
        <h3>ğŸ¯ ç‰¹å®šã•ã‚ŒãŸåŒä¸€ã‚«ãƒ¼ãƒ‰ (ä¸Šä½10çµ„)</h3>
        <table>
        <tr><th>Aç¤¾ã‚«ãƒ¼ãƒ‰</th><th>Bç¤¾ã‚«ãƒ¼ãƒ‰</th><th>ãƒãƒƒãƒã‚¹ã‚³ã‚¢</th><th>ãƒãƒƒãƒæ ¹æ‹ </th></tr>
        """
        
        for match in display_matches:
            card_a = match['card_a']
            card_b = match['card_b']
            
            name_a = card_a.get('name', card_a.get('serial', 'Unknown'))
            name_b = card_b.get('ã‚«ãƒ¼ãƒ‰å', card_b.get('å‹ç•ª', 'Unknown'))
            
            html += f"""
            <tr>
                <td><strong>{name_a}</strong></td>
                <td><strong>{name_b}</strong></td>
                <td class="confidence-high">{match['overall_similarity']:.3f}</td>
                <td>{len(match.get('similarity_details', {}))}ä»¶ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è‡´</td>
            </tr>
            """
        
        html += "</table>"
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°è¡¨ç¤º
    if display_mappings:
        html += """
        